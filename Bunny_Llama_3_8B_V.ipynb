{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOeJBTQ0CKgpukUl4Iv/ri1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Javad-Manashti/yolov8m-pothole-segmentation/blob/main/Bunny_Llama_3_8B_V.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Bunny-LLama-3 to works as an annotator for validating and analyzing the results of model Yolo pothole detection\n",
        "\n",
        "https://huggingface.co/BAAI/Bunny-Llama-3-8B-V?utm_source=tldrai"
      ],
      "metadata": {
        "id": "LO63BzEKORGo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paWXxZBxHxFp"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers accelerate pillow\n",
        "!pip install accelerate\n",
        "!pip uninstall torch torchvision -y\n",
        "!pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from PIL import Image\n",
        "import warnings\n",
        "from huggingface_hub import HfFolder\n",
        "\n",
        "# Set environment variable for better memory allocation management\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Clear cached memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Set the device to GPU (CUDA)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Authenticate with Hugging Face Hub\n",
        "hf_token = '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'  # Replace with your actual token\n",
        "HfFolder.save_token(hf_token)\n",
        "\n",
        "# Specify the model name\n",
        "model_name = 'BAAI/Bunny-Llama-3-8B-V'\n",
        "\n",
        "# Load the model and tokenizer and move them to the GPU\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True\n",
        ").to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name\n",
        ")\n",
        "\n",
        "# Shortened text prompt setup\n",
        "prompt = \"Review the attached image for pothole coverage in red and assess detection accuracy.\"\n",
        "text = f\"USER: <image>\\n{prompt} ASSISTANT:\"\n",
        "input_ids = tokenizer(text, return_tensors='pt').input_ids.to(device).long()\n",
        "\n",
        "\n",
        "# Load and process the image\n",
        "image_path = '/content/image5-phs.jpg'  # Update the path to where your image is stored\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Process the image, ensure this function is defined or use appropriate preprocessing\n",
        "# Make sure to check the expected format for 'process_images' method if it's available in the model\n",
        "image_tensor = model.process_images([image], model.config).to(device).to(torch.float16)\n",
        "\n",
        "# Generate response using the model\n",
        "output_ids = model.generate(\n",
        "    input_ids,\n",
        "    images=image_tensor,  # Ensure the 'images' parameter is supported by the model\n",
        "    max_new_tokens=1000,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "# Decode the output\n",
        "response = tokenizer.decode(output_ids[len(input_ids[0]):], skip_special_tokens=True)\n",
        "print(response.strip())\n"
      ],
      "metadata": {
        "id": "6t8kSdAFYMUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shortened text prompt setup\n",
        "prompt = \"Review the attached image for pothole coverage in red and assess detection accuracy.\"\n",
        "text = f\"USER: <image>\\n{prompt} ASSISTANT:\"\n",
        "input_ids = tokenizer(text, return_tensors='pt').input_ids.to(device).long()\n",
        "\n",
        "\n",
        "# Load and process the image\n",
        "image_path = '/content/image5-phs.png'  # Update the path to where your image is stored\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Process the image, ensure this function is defined or use appropriate preprocessing\n",
        "# Make sure to check the expected format for 'process_images' method if it's available in the model\n",
        "image_tensor = model.process_images([image], model.config).to(device).to(torch.float16)\n",
        "\n",
        "# Generate response using the model\n",
        "output_ids = model.generate(\n",
        "    input_ids,\n",
        "    images=image_tensor,  # Ensure the 'images' parameter is supported by the model\n",
        "    max_new_tokens=50,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "# Decode the output\n",
        "response = tokenizer.decode(output_ids[len(input_ids[0]):], skip_special_tokens=True)\n",
        "print(response.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7UyGxgVdybj",
        "outputId": "d32eaeb7-9842-42f5-999c-b18af60fe4fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgrgBCZyfJ-R",
        "outputId": "53efe4c8-d526-4e72-b6cf-10cc52caaa85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[128000,   6584,     25,    366,   1843,    397,  19997,    279,  12673,\n",
            "           2217,    369,   3273,    339,   1286,  10401,    304,   2579,    323,\n",
            "           8720,  18468,  13708,     13,  36660,   3931,   2891,     25,    358,\n",
            "           2846,  14931,     11,    719,    439,    264,   4221,   1646,     11,\n",
            "            358,   4250,   1684,   5448,     13,   4452,     11,    358,    649,\n",
            "           3493,    499,    449,   1063,   4689,   2038,    389,   1268,    311,\n",
            "           8720,    279,  13708,    315,   3273,    339,   1286,  18468,   1701,\n",
            "           5448,    382,   1271,   8720,    279,  13708,    315,   3273,    339,\n",
            "           1286,  18468,   1701,   5448,     11,    499,    649,   1833,   1521,\n",
            "           7504,   1473,     16,     13,  21153,    264,  10550,    315,   5448,\n",
            "            430,   6782,   3273,    339,   7298,    323,   5448,    430,    656,\n",
            "            539,   6782,   3273,    339,   7298,    627,     17,     13,   5560,\n",
            "            264,   5780,   6975,  12384,    311,   5542,    264,   1646,    311,\n",
            "          11388,   3273,    339,   7298,    304,    279,   5448,    627,     18,\n",
            "             13,  55215,    279,   5178,    315,    279,   1646,   1701,  17150,\n",
            "           1778,    439,  16437,     11,  19635,     11,    323,    435,     16,\n",
            "           5573,    627,     19,     13,  24702,    279,   5178,    315,    279,\n",
            "           1646,    449,   1023,   4211,    477,   5528,    311,   8417,    902,\n",
            "            832,    374,    279,   1455,  13687,    627,     20,     13,   3475,\n",
            "            279,   1646,    389,    264,    502,    743,    315,   5448,    311,\n",
            "           1518,   1268,   1664,    433,   4689,   4861,    311,    502,    828,\n",
            "            382,   2181,    596,   3062,    311,   5296,    430,    279,  13708,\n",
            "            315,   3273,    339,   1286,  18468,   1701,   5448,    649,    387,\n",
            "          11754,    555,   9547,   1778,    439,  18186,   4787,     11,   2217,\n",
            "           4367,     11,    323,    279,   1404,    323,   6211,    315,    279,\n",
            "           3273,    339,   1286,     13,  15636,     11,    433,    596,   3062,\n",
            "            311,  15884,   3373,    323,  54565,    279,   5448,   1603,   4967,\n",
            "            279,   1646,     13, 128001]], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}